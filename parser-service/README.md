<h3>Микросервис загрузки изображений с сайта</h3>

Краткое ТЗ: соскрапить 1000+ изображений разных категорий с сайта:
 https://саратов.хищник.рф". Изображения должны иметь имена представляющих их товаров с добавлением категории товара. 

О микросервисе: веб-сервис для скраппинга изображений и ссылок на товары.
В качестве фреймворка для API HTTP задействован Python FastAPI, для хранения данных используется БД PostgreSQL.

Краткий прицнип работы:
1.Для начала берется список категорий товаров в формате: <название категории>|<ссылка на всю категорию>|<количество страниц для скраппинга в категории>
P.S. - если количество страниц = 0, значит будет обработана лишь одна страница.
Функция - read_links()

2.Скраппер начинает собирать информацию о товарах и загружать их в БД в формате:
<Категория товара><Название товара><Ссылка на страницу товара><Ссылка для скачивания изображения товара>
Основная функция - ParseLinks() 

3.Скраппер берет из БД данные, собранные из 2 пункта и скачивает картинку.
Основная функция - startScrapper()

Дополнительный функционал: 
1.Возможность прерывания процесса скраппинга изображений, с запоминанием последней скаченной картинки. 
2.Возможность очистки БД.
3.Модуль транслитерации
4.Вывод состояния процесса загрузки в консоль (по средствам tqdm и time)

<h3>WEB функционал </h3>
GET /Start - основная функция скраппера. Выполняет "чистый" скраппинг. 
(Под "чистым" предполагается очистка всей прошлой информации в БД, а так же всех временных файлов, в том числе и файла, отвечающего за отслеживание номера последней скачанной картинки)
GET /Clear - Второстепенная функция скраппера. Относится к "ручному" режиму. Очищает всю информацию с БД
GET /Parse/Links (Images) - функции для управления скраппером в ручном режиме. Отвечают за скраппинг ссылок и информации на товары и скраппинг изображений соответственно
Управление и отправка запросов осуществляется по средствам Swager UI

